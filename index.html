<!doctype html>
<html lang="en">
  <head>
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link
      href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <link rel="icon" href="https://pbs.twimg.com/profile_images/1242741510929612801/Mt1ozX07_400x400.jpg">
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>SCOPE Workshop @ ICLR 2025</title>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
    />
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

    <!-- Latest compiled and minified JavaScript -->
    <script
      src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
      integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
      crossorigin="anonymous"
    ></script>

    <link
      rel="stylesheet"
      href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css"
    />
    <!-- Custom styles for this template -->

    <link href="../css/scrolling-nav.css" rel="stylesheet" />
    <link href="../css/style.css" rel="author stylesheet" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-0M445FTS98"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-0M445FTS98");
    </script>

    <style>
      #tpc p {
        margin-bottom: 0.3em;
        font-size: 0.85em;
      }
    </style>
  </head>

  <body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light" id="mainNav">
      <div class="container bar-container">
        <a class="title-head" href="#page-top">SCOPE Workshop @ ICLR 2025</a>
        <button
          class="navbar-toggler"
          type="button"
          data-toggle="collapse"
          data-target="#navbarResponsive"
          aria-controls="navbarResponsive"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#cfp">CFP</a>
            </li>

            <li class="nav-item"></li>
              <a class="nav-link js-scroll-trigger" href="#schedule">Schedule</a>
            </li>

            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#speakers"
                >Invited Speakers</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="/accepted_paper.html#papers"
                >Accepted Papers</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#organizers"
                >Organizers</a
              >
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#sponsors"
                >Sponsors</a
              >
            </li>
            <!-- <li class="nav-item"></li>
              <a class="nav-link js-scroll-trigger" href="#tpc"
                >TPC Members</a
              >
            </li> -->
          </ul>
        </div>
      </div>
    </nav>

    <header
      class="headercontainer bg-primary text-white"
      style="padding: 0%; max-height: none"
    >
      <div style="background-color: rgba(160, 160, 160, 0)" class="text-center">
        <div
          style="
            padding-bottom: 6%;
            padding-top: 6%;
            background-image: url(&quot;../images/Singapore.jpg&quot;);
            background-size: cover;
            background-position: center;
          "
        >
          <div
            class="container titlebox"
            ;
            style="
              display: inline-block;
              background-color: rgba(0, 0, 0, 0.7);
              width: auto;
            "
          >
            <p style="text-align: center; margin-bottom: 2" class="title">
              ICLR 2025 Workshop on
              <br />
              <u>Sc</u>alable <u>Op</u>timization for <u>E</u>fficient
              and Adaptive Foundation Models
              <br />
              <strong>(SCOPE)</strong>
            </p>
            <p
              style="text-align: center; margin-bottom: 0; font-size: 1em"
              class="subtitle"
            >
              <!-- Placeholder -- one sentence descroption. -->
            </p>
            <br />
            <p style="text-align: center; margin-bottom: 0" class="subtitle">
              Monday, April 28th, 2025
            </p>
            <p style="text-align: center; margin-bottom: 0" class="subtitle">
              collocated with
              <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a>

              in Singapore
            </p>
          </div>
        </div>
      </div>
    </header>

    <!-- <section id="about">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">News</span>
            <br />
            <p> TBA </p>
          </div>
        </div>
      </div>
    </section> -->

    <!-- <hr class="half-rule" /> -->
    <section id="about">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">About</span>
            <br />
            <p>In the rapidly evolving landscape of AI, the development of scalable optimization methods to yield efficient and adaptive foundation models has significant demand in the space of their inference service. In specific, enabling model efficiency while allowing them to be adaptable to various new downstream tasks has multifold challenges.  </p>

            <p>Firstly, the model's ability to quickly learn adaptive and efficient sub-model selection on different tasks requires the capability to perform continual weight updates, compute- and memory-efficient fine-tuning, and personalized adaptation. </p>

            <p>Secondly, with the increased demand for long context understanding and reasoning, the model needs to yield such efficient adaptation with the informative usefulness of the query-specific token fetching. For instance, imagine a model that continually learns from current news events, adapting to the ever-changing global landscape by integrating up-to-date knowledge. Such models may not only need efficient fine-tuning to new incoming data stream, but also understand efficient handling of the KV cache that may keep on growing with the requirement to handle longer contextual information. Additionally, the integration of retrieval-augmented generation (RAG) into foundation models can ensure that generated content is not only relevant, but also reflects the most current knowledge while costing the prefill size to go up. </p>

            <p>Thirdly, with such growing demand for contextual adaptation, mixture of experts (MoE) models have also received significant traction that can perform test time adaptation via learned routing policy. In addition, the emergence of sub-quadratic models with constant KV states as opposed to KV caching of transformers, has opened up a new avenue of the model's adaptation ability in the context of information retention into compressive KV states. These capabilities rely on techniques for adapting foundation models, including fine-tuning, conversion, distillation, and in-context/few-shot learning. </p>

            <p>This workshop aims to <b>capture advances in scalable, adaptive fine-tuning, calibration, and conversion to yield inference efficient quadratic and sub-quadratic foundation models, focusing on methodologies across vision, language, and multi-modal domains.</b> Hosting this workshop at ICLR aligns with the conference’s mission to advance the frontiers of machine learning. The workshop aims to bring together interdisciplinary researchers from core ML/DL, efficient ML, computer vision, and NLP.</p>


          </div>
        </div>
      </div>
    </section>

    <hr class="half-rule" />
    <section id="cfp">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Call for Papers</span><br />

            <p>This SCOPE workshop encourages submissions on novel algorithms, research results, and work-in-progress research on building scalable optimization for efficient and adaptive foundation models.
            We welcome high-quality original papers in the following <u>two</u> tracks:

            <ul>
              <li style="padding-bottom: 10px"> <b>Short/tiny paper track:</b> with a maximum limit of <u>2 pages</u> (as per the guideline of ICLR 2025 tiny paper track), excluding references and appendix. </li>
              <li style="padding-bottom: 10px"> <b>Main paper track: </b> with a maximum limit of <u>5 pages</u> (with ICLR 2025 style files and templates), excluding references and appendix.</li>
          </ul>

          <p>Outstanding papers will be selected for oral presentation, while all accepted papers will be allowed to be presented as posters.</p>

          <h4>Submission Link: </h4>
          <p>You can submit your papers on <a href="https://openreview.net/group?id=ICLR.cc/2025/Workshop/SCOPE&referrer=%5BHomepage%5D(%2F)#tab-your-consoles">SCOPE OpenReview page</a>.</p>

            <h4>Important dates: </h4>
            <p>
              All deadlines are
              <a href="https://www.timeanddate.com/time/zones/aoe">anywhere on earth (AoE) time</a>.
            </p>

            <table class="table table-striped table-sm">
              <tbody>

                <tr>
                  <td class="font-weight-bold" style="width: 40%">
                    Paper submission deadline
                  </td>
                  <td style="width: 40%">Sunday, February 9th, 2025</td>
                </tr>

                <tr>
                  <td class="font-weight-bold" style="width: 40%">
                    Reviewing deadline
                  </td>
                  <td style="width: 40%">Monday, February 24th, 2025</td>
                </tr>

                <tr>
                  <td class="font-weight-bold" style="width: 40%">
                    Author notificiation
                  </td>
                  <td style="width: 40%">Wednesday, March 5th, 2025</td>
                </tr>

                <tr>
                  <td class="font-weight-bold" style="width: 40%">
                    Camera-ready copy (CRC) deadline
                  </td>
                  <td style="width: 40%">Wednesday, March 26th, 2025</td>
                </tr>

              </tbody>
            </table>

            <!-- <p><b>Topics:</b></p> -->
            <h4>Topics:</h4>

            <p>The relevant topics of interest at this workshop include (but are not limited to):</p>

            <ul>
              <li style="padding-bottom: 10px"> Efficient Long Context Understanding</li>
              <li style="padding-bottom: 10px"> Sub-Quadratic Models for Foundational Tasks and Personalization</li>
              <li style="padding-bottom: 10px"> Quadratic to Sub-Quadratic Model Conversion</li>
              <li style="padding-bottom: 10px"> Task Specific Adaptive Foundation Models</li>
              <li style="padding-bottom: 10px"> Retrieval Augmented Generation for Efficient Contextual Processing</li>
              <li style="padding-bottom: 10px"> Efficient Sub-Quadratic Foundation Models</li>
              <li style="padding-bottom: 10px"> Adaptive Fine-Tuning for Multimodal Foundation Models</li>
              <li style="padding-bottom: 10px"> Efficient Fine-Tuning for Continual Adaptation and Personalization</li>
              <li style="padding-bottom: 10px"> Model Optimization for Latency and Throughput Efficient Inference</li>
              <li style="padding-bottom: 10px"> Adaptive Routing with Mixture of Experts</li>
          </ul>

          <h4>General Guideline: </h4>
          <p><b>Format:</b> All submissions must be in PDF format using the ICLR 2025 LaTeX style file . Please include the references and appendix in <b>the same PDF as the main paper</b>. The maximum file size for submissions is 50MB. Submissions that violate the ICLR style (e.g., by decreasing margins or font sizes) or page limits criteria of the workshop, may be rejected without further review.</p>

          <p><b>Double-Blind Reviewing:</b> The reviewing process will be double blind. As an author, you are responsible for anonymizing your submission. In particular, you should not include author names, author affiliations, or acknowledgements in your submission and you should avoid providing any other identifying information (even in the supplementary material or in the shared Github code link).</p>

          <p><b>Dual-Submission Policy:</b> We welcome ongoing and unpublished works. Authors are also encouraged to submit papers that are under review at any venue (e.g.TMLR under review) at the time of submission. In such cases, please be mindful about maintaining the anonymity for the other submission. For example, submission with the exact same paper title and exact same content as the other one, is discouraged. Authors are <b>strongly discouraged</b> to submit their previously accepted works that are already <b>accepted and presented before ICLR’25</b>.  </p>

          <p><b>Non-Archival:</b> The workshop is a non-archival venue and will not have official proceedings. Workshop submissions can be subsequently or concurrently submitted to other venues. </p>

          <p><b>Visibility:</b> Submissions and reviews will not be made public. Only accepted papers across the different tracks will be made public on the workshop website.</p>

          <p><b>Tiny Paper Track:</b> We encourage the submission of diverse forms of preliminary work through the Tiny Papers Track. This year, ICLR is discontinuing the separate “Tiny Papers” track, and is instead requiring each workshop to accept short (exact page length to be determined by each workshop) paper submissions, with an eye towards diversity and inclusion; see <a href="https://iclr.cc/Conferences/2025/CallForTinyPapers">call for tiny papers</a>
          for more details. Authors of these papers will be earmarked for potential funding from ICLR, but need to submit a separate application for Financial Assistance that evaluates their eligibility. This application for Financial Assistance to attend ICLR 2025 will become available on <a href="https://iclr.cc/Conferences/2025/">this link</a> at the beginning of February and close on March 2nd. The goal of the <u>Tiny Papers Track</u> is to build on top of previous ICLR Tiny Papers track efforts to encourage submissions from under-represented, under-resourced, and budding researchers who may not (yet) have the resources to submit full papers. SCOPE-ICLR 2025 aims to leverage the Tiny Papers track to broaden participation across the diversity of research topics centered around scalable and efficient foundation models. We welcome submissions that provide new ideas or fresh perspectives to tackle some of the challenging problems under this theme. We encourage submissions up to <b>2 pages</b> (excluding references and appendix) in length for tiny papers using the ICLR 2025 template (no abstract is required). Reviewers will be asked to evaluate the clarity, correctness, and potential reproducibility of the submissions. Submissions from underrepresented groups are especially encouraged.</p>



          </div>
        </div>
      </div>
    </section>

    <!-- <hr class="half-rule" />

    <section id="schedule">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Schedule</span><br />

            TBA

          </div>
        </div>
      </div>
    </section> -->
    <hr class="half-rule" />

    <section id="schedule">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Schedule</span><br />
                    <div class="row centered">
                        <table class="table table-striped"  cellpadding="2" cellspacing="2">
                          <tbody>
                              <tr>
                                <td style="width: 20%;">Time</td>
                                <td style="width: 80%;">Events</td>
                              </tr>
                              <tr>
                                  <td>08:30 - 08:45 </td>
                                  <td><b><i>Welcome and Introduction</i></b></td>
                              </tr><tr>
                                  <td>08:45 - 09:15 </td>
                                  <td><b><i>Invited Talk 1: Yu Cheng</i></b>
                                  <br />
                                  <b>Building Efficient and Scalable Foundation Models with Linear and Sparse Architecture</b>
                                  </td>
                              </tr><tr>
                                  <td>09:15 - 9:45 </td>
                                  <td><b><i>Invited Talk 2: Zechun Liu</i></b>
                                  <br />
                                  <b>Advancing Large Language Models in Resource-Constrained Environments</b>
                                  </td>
                              </tr><tr>
                                <td>09:45 - 10:15 </td>
                                  <td><b><i>Invited Talk 3: Zhangyang Wang </i></b>
                                    <br />
                                    <b>HALoS: Hierarchical Asynchronous Local SGD over Slow Networks for Geo-Distributed LLM Training</b>
                                  </td>
                              </tr><tr>
                                  <td>10:15 - 10:30</td>
                                  <td><span style="color: red; font-weight: bold;">Coffee Break</span></td>
                              </tr><tr>
                                  <td>10:30 - 10:40 </td>
                                  <td><b><i> Spotlight Papers I: M2R2: Efficient Transformers with Mixture of Multi-Rate Residuals</i></b></td>
                              </tr><tr>
                                  <td>10:40 - 10:50 </td>
                                  <td><b><i> Spotlight Papers I: Towards Infinite-Long Prefix in Transformers</i></b></td>
                              </tr><tr>
                                  <td>10:50 - 11:00 </td>
                                  <td><b><i> Spotlight Papers I: SageAttention2: Efficient Attention with Smoothing Q and Per-thread Quantization</i></b> </td>
                              </tr><tr>
                                  <td>11:00 - 12:00 </td>
                                  <td>Morning Poster Session</td>
                              </tr><tr>
                                  <td>12:00 - 13:00 </td>
                                  <td><span style="color: red; font-weight: bold;">Lunch Break</span></td>
                              </tr><tr>
                                  <td>13:00 - 13:30 </td>
                                  <td><b><i>Invited Talk 4: Zhuang Liu</i></b>
                                  <br />
                                  <b> Transformers without Normalization</b>
                                  </td>
                              </tr><tr>
                                  <td>13:30 - 14:00 </td>
                                  <td><b><i>Invited Talk 5: Bryan Low</i></b>
                                  <br />
                                  <b>Efficient Prompt Optimization for Adaptive LLMs: Instruction and Exemplar Tuning via Neural Bandits</b>
                                  </td>
                              </tr>
                              <tr>
                                  <td>14:00 - 14:10 </td>
                                  <td><b><i> Spotlight Papers II: Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity</i></b></td>
                              </tr>
                              <tr>
                                  <td>14:10 - 14:20 </td>
                                  <td><b><i> Spotlight Papers II: Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts</i></b></td>
                              </tr>
                              <tr>
                                  <td>14:20 - 14:30 </td>
                                  <td><b><i> Spotlight Papers II: LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree Drafting for Visual Auto-regressive Models</i></b></td>
                              </tr>
                              <tr>
                                  <td>14:30 - 14:40 </td>
                                  <td><b><i> Spotlight Papers II: Overtrained Language Models Are Harder to Fine-Tune</i></b></td>
                              </tr>
                              <tr>
                                  <td>14:40 - 14:50 </td>
                                  <td><b><i> Spotlight Papers II: STIV: Scalable Text and Image Conditioned Video Generation</i></b></td>
                              </tr>
                              <tr>
                                  <td>14:50 - 15:00 </td>
                                  <td><b><i> Spotlight Papers II: ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals</i></b></td>
                              </tr>
                              <tr>
                                  <td>15:00 - 15:15 </td>
                                  <td><span style="color: red; font-weight: bold;">Coffee Break</span></td>
                              </tr><tr>
                                  <td>15:15 - 15:45 </td>
                                  <td><b><i>Invited Talk 6: Pavlo Molchanov</i></b>
                                  <br />
                                  <b>Efficient LLMs via Compression and Architecture Design</b>
                                  </td>
                              </tr><tr>
                                  <td>15:45 - 16:15 </td>
                                  <td><b><i>Invited Talk 7: Ziwei Liu</i></b>
                                  <br />
                                  <b>From Multimodal Generative Models to Dynamic World Modeling</b>
                                  </td>
                              </tr><tr>
                                  <td>16:15 - 16:45 </td>
                                  <td><b><i>Panel Discussion</i></b></td>
                              </tr><tr>
                                  <td>16:45 - 17:00</td>
                                  <td>Closing Remarks</td>
                              </tr><tr>
                                  <td>17:00 - 18:00</td>
                                  <td>Afternoon Poster Session</td>
                              </tr></tbody>

                        </table>
                    </div>
          </div>
        </div>
      </div>
    </section>


    <hr class="half-rule" />

    <section id="speakers">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec"> Invited Speakers </span><br />

            <div class="row">
              <a href="https://ych133.github.io/">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://ych133.github.io/images/profile0.png"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://ych133.github.io/">
                      Yu Cheng</a
                    >
                  </p>
                  <p class="institution">Chinese University of Hong Kong</p>
                </div>
              </a>

              <a href="https://www.pmolchanov.com/">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://www.pmolchanov.com/authors/pavlo/avatar_hu00aa34e1004cb0316eb02ea199a64fa4_11292633_270x270_fill_lanczos_center_3.png"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://www.pmolchanov.com/"> Pavlo Molchanov </a>
                  </p>
                  <p class="institution">NVIDIA Research</p>
                </div>
              </a>

              <a href="https://zechunliu.com/">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://zechunliu.com/pictures/1_photo.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://zechunliu.com/"> Zechun Liu </a>
                  </p>
                  <p class="institution">Meta Reality Labs</p>
                </div>
              </a>

              <a href="https://vita-group.github.io/index.html">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=pxFyKAIAAAAJ&citpid=6"
                    class="figure-img img-fluid"
                  />
                  <p class="profname2line">
                    <a href="https://vita-group.github.io/index.html">
                      Zhangyang (Atlas) Wang</a
                    >
                  </p>
                  <p class="institution">XTX Markets & University of Texas at Austin</p>
                  <!-- <p class="institution">XTX Markets & University of Texas at Austin</p> -->
                </div>
              </a>
            </div>

            <!-- 2nd row-->
            <div class="row">


              <a href="https://liuzhuang13.github.io/">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://liuzhuang13.github.io/images/zhuangliuc.png"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://liuzhuang13.github.io/"> Zhuang Liu  </a>
                  </p>
                  <p class="institution" style="height: 90px;">Meta FAIR</p>
                </div>
              </a>

              <a href="https://www.comp.nus.edu.sg/~lowkh/index.html">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://www.comp.nus.edu.sg/~lowkh/assets/portraits/bryan.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://www.comp.nus.edu.sg/~lowkh/index.html"> Bryan Low </a>
                  </p>
                  <p class="institution" style="height: 90px;">National University of Singapore & AI Singapore</p>
                </div>
              </a>

              <a href="https://liuziwei7.github.io/">
                <div class="profpic xlarge-1 speaker columns">
                  <img
                    src="https://liuziwei7.github.io/homepage_files/me.png"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://liuziwei7.github.io/">
                      Ziwei Liu</a
                    >
                  </p>
                  <p class="institution">Nanyang Technological University</p>
                  <!-- <p class="institution">XTX Markets & University of Texas at Austin</p> -->
                </div>
              </a>
            </div>

            <!-- <div class="row">
            </div> -->
          </div>
        </div>
      </div>
    </section>

    <br />
    <hr class="half-rule" />

    <!-- <hr class="half-rule" />/ -->
    <section id="organizers">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Organizers</span><br />
            <div class="row">
              <a href="https://ksouvik52.github.io/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/souvik.jpeg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://ksouvik52.github.io/">
                      Souvik Kundu
                    </a>
                  </p>
                  <p class="institution">Intel</p>
                </div>
              </a>

              <a href="https://tianlong-chen.github.io/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/tianlong.jpeg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://tianlong-chen.github.io/">
                      Tianlong Chen</a
                    >
                  </p>
                  <p class="institution">University of North Carolina at Chapel Hill</p>
                </div>
              </a>

              <a href="https://shiweiliuiiiiiii.github.io/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/shiwei.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://shiweiliuiiiiiii.github.io/"> Shiwei Liu</a>
                  </p>
                  <p class="institution">University of Oxford</p>
                </div>
              </a>

              <a href="http://zhenghaizhong.com/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/haizhong.jpeg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="http://zhenghaizhong.com/"> Haizhong Zheng </a>
                  </p>
                  <p class="institution">Carnegie Mellon University</p>
                </div>
              </a>
            </div>

            <div class="row">
              <a href="https://www.ayazdan.com/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/amir.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a
                      href="https://www.ayazdan.com/"
                    >
                    Amir Yazdanbakhsh</a
                    >
                  </p>
                  <p class="institution">Google DeepMind</p>
                </div>
              </a>

              <a href="https://www.andrew.cmu.edu/user/beidic/">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/beidi.jpeg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://www.andrew.cmu.edu/user/beidic/">
                      Beidi Chen</a
                    >
                  </p>
                  <p class="institution">Carnegie Mellon University</p>
                </div>
              </a>

              <a href="https://eiclab.scs.gatech.edu/pages/team.html">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/yingyan.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://eiclab.scs.gatech.edu/pages/team.html">
                      Yingyan (Celine) Lin</a
                    >
                  </p>
                  <p class="institution">Georgia Institute of Technology</p>
                </div>
              </a>

              <a href="https://scholar.google.com/citations?hl=en&user=X7a38bAAAAAJ&view_op=list_works&sortby=pubdate">
                <div class="profpic xlarge-1 columns">
                  <img
                    src="../images/organizers/farshad.jpg"
                    class="figure-img img-fluid"
                  />
                  <p class="profname">
                    <a href="https://scholar.google.com/citations?hl=en&user=X7a38bAAAAAJ&view_op=list_works&sortby=pubdate">
                      Farshad Firouzi</a
                    >
                  </p>
                  <p class="institution">Arizona State University
                    <br>
                    (Finance Chair)
                  </p>
                </div>
              </a>

            </div>
          </div>
        </div>
      </div>
    </section>

    <br />
    <hr class="half-rule" />
    <section id="tpc">
      <div class="container">
        <div class="row">
          <div class="col-md-12 mx-auto">
            <span class="titlesec">TPC Members</span><br />
            <h4>Outstanding Reviewers</h4>
            <div class="row">
              <div class="col-md-6">
                <p>Boqian Wu, University of Twente</p>
                <p>Min-Hung Chen, NVIDIA</p>
                <p>Phitchaya Mangpo Phothilimthana, Google</p>
                <p>Rui-Jie Zhu, University of California, Santa Cruz</p>
                <p>Seyedarmin Azizi, University of Southern California</p>
                <p>Shamik Kundu, Intel</p>
              </div>
              <div class="col-md-6">
                <p>Shulin Tian, Nanyang Technological University</p>
                <p>Song Wang, University of Virginia</p>
                <p>Sreetama Sarkar, University of Southern California</p>
                <p>Themistoklis Haris, Boston University</p>
                <p>Yuxin Zhang, Xiamen University</p>
              </div>
            </div>



            <h4>Reviewers</h4>

            <div class="row">
              <div class="col-md-6">
                  <p>Abhimanyu Rajeshkumar Bambhaniya, Georgia Institute of Technology</p>
                  <p>Abhishek Tyagi, University of Rochester</p>
                  <p>Advait Gadhikar, CISPA Helmholtz Center for Information Security</p>
                  <p>Akshat Ramachandran, Georgia Institute of Technology</p>
                  <p>Amir Ziashahabi, University of Southern California</p>
                  <p>Apivich Hemachandra, National University of Singapore</p>
                  <p>Arnab Raha, Purdue University</p>
                  <p>Aviv Bick, Carnegie Mellon University</p>
                  <p>Ayan Chakraborty, EPFL - EPF Lausanne</p>

                  <p>Bahar Asgari, University of Maryland, College Park</p>
                  <p>Benedikt Schesch, ETH Zurich</p>
                  <p>Bingli Wang, Sichuan Agricultural University</p>
                  <p>Boxun Xu, University of California, Santa Barbara</p>
                  <p>Chandramouli Amarnath, Georgia Institute of Technology</p>
                  <p>Chaojian Li, Georgia Institute of Technology</p>
                  <p>Destiny Okpekpe, ELLIS Institute Tübingen</p>
                  <p>Doohyuk Jang, Korea Advanced Institute of Science & Technology</p>
                  <p>Elisa Tsai, University of Michigan - Ann Arbor</p>
                  <p>Esha Singh, University of California, San Diego</p>

                  <p>Fu-En Yang, NVIDIA</p>
                  <p>Gabriela Ben-Melech Stan, Intel</p>
                  <p>Geonhwa Jeong, Meta</p>
                  <p>Ghulam Ahmed Ansari, LinkedIn</p>
                  <p>Haihao Shen, Intel</p>
                  <p>Haiyun Lyu, University of North Carolina at Chapel Hill</p>
                  <p>Hanshi Sun, ByteDance Inc.</p>
                  <p>Hao Kang, Georgia Institute of Technology</p>
                  <p>Haofeng Huang,  Tsinghua University</p>
                  <p>Harry Dong, Carnegie Mellon University</p>
                  <p>Henry Ndubuaku, Queen Mary, University of London</p>

                  <p>Huaizhi Qu, University of North Carolina at Chapel Hill</p>
                  <p>Hyoukjun Kwon, University of California, Irvine</p>
                  <p>Jason Clemons, NVIDIA</p>
                  <p>Jian Chen, CMU, Carnegie Mellon University</p>
                  <p>Jian Meng, Cornell University</p>
                  <p>Jiayi Xin, University of Pennsylvania</p>
                  <p>Jihai Zhang, The Chinese University of Hong Kong</p>
                  <p>Jinhao Duan, Drexel University</p>
                  <p>Jintao Zhang, Tsinghua University</p>

                  <p>Lei Gao, University of Southern California</p>
                  <p>Longwei Yang, North Carolina State University</p>
                  <p>Lu Yin, University of Surrey</p>
                  <p>Mark Zhao, Stanford University</p>
                  <p>Minkyoung Cho, University of Michigan - Ann Arbor</p>
                  <p>Mohammed Abdul Al Arafat Tanzin, BRAC University</p>
                  <p>Mohan Zhang, University of Science and Technology of China</p>
                  <p>Mufan Qiu, University of North Carolina at Chapel Hill</p>
                  <p>Nilesh Prasad Pandey, University of California, San Diego</p>

                  <p>Payman Behnam, Georgia Institute of Technology</p>
                  <p>Pingzhi Li, University of North Carolina at Chapel Hill</p>
                  <p>Qiao Xiao, Eindhoven University of Technology</p>
                </div>
              <div class="col-md-6">
                <p>Rana Shahroz, University of North Carolina at Chapel Hill</p>
                <p>Ritik Raj, Georgia Institute of Technology</p>
                <p>Rohan Mahapatra, University of California, San Diego</p>
                <p>Ruichen Zhang, University of North Carolina at Chapel Hill</p>

                <p>Saksham Consul, Blackforest Labs Inc</p>
                <p>Sakshi Choudhary, Purdue University</p>
                <p>Santosh Pandey, Rutgers University</p>
                <p>Sathya Krishnan Suresh, Nanyang Technological University</p>
                <p>Sean McPherson, Intel</p>
                <p>Sepidehsadat Hosseini, Borealis AI</p>
                <p>Sharath Nittur Sridhar, Intel Labs</p>
                <p>Shibo Zhang, Samsung</p>
                <p>Shuowei Jin, University of Michigan - Ann Arbor</p>
                <p>Shvetank Prakash, Harvard University</p>
                <p>Sihwan Park, Korea Advanced Institute of Science & Technology</p>

                <p>Simla Burcu Harma, EPFL - EPF Lausanne</p>
                <p>Songlin Yang, Massachusetts Institute of Technology</p>
                <p>Srikant Bharadwaj, Microsoft</p>
                <p>Su Hyeong Lee, University of Chicago</p>
                <p>Subhajit Dutta Chowdhury, AMD</p>
                <p>Sumit Kumar Mandal, Indian Institute of Science, Bangalore</p>
                <p>Theo X. Olausson, Massachusetts Institute of Technology</p>
                <p>Tianqi Tang, Meta</p>
                <p>Timo Wunderlich, Charite</p>
                <p>Tz-Ying Wu, Intel</p>

                <p>Uday Mallappa, Intel</p>
                <p>Utkarsh Saxena, Purdue University</p>
                <p>Wenhua Cheng, Intel</p>
                <p>Xiaoyan Bai, University of Chicago</p>
                <p>Xin Li, University of Science and Technology of China</p>
                <p>Xinhang Chen, Independent</p>
                <p>Xinyu Zhao, University of North Carolina at Chapel Hill</p>
                <p>Xuchen Gong, University of Chicago</p>
                <p>Xueshen Liu, University of Michigan - Ann Arbor</p>
                <p>Yang Zhang, National University of Singapore</p>

                <p>Yi-Chien Lin, University of Southern California</p>
                <p>Yonggan Fu, Georgia Institute of Technology</p>
                <p>Youngeun Kim, Meta</p>
                <p>Yuhang Chen, Wuhan University</p>
                <p>Zeyu Liu, University of Southern California</p>
                <p>Zhaoxuan Wu, Singapore-MIT Alliance for Research and Technology</p>
                <p>Zhenyu Zhang, University of Texas at Austin</p>
                <p>Zhifan Ye, Georgia Institute of Technology</p>
                <p>Zhiliang Chen, National University of Singapore</p>
                <p>Zhuoming Chen, Carnegie Mellon University</p>

                <p>Ziang Cao, Nanyang Technological University</p>
                <p>Zijie Liu, Washington University, Saint Louis</p>
                <p>Zirui Liu, University of Minnesota - Twin Cities</p>
                <p>Zishen Wan, Georgia Institute of Technology</p>
                <p>Zongyu Lin, University of California, Los Angeles</p>
              </div>
            </div>

            <br />
          </div>

        </div>
      </div>
    </section>

    <br />
    <hr class="half-rule" />

    <section id="sponsors">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Sponsors</span><br />

            <div class="row">
              <a href="https://www.intel.com/content/www/us/en/homepage.html">
                <img src="../images/intel-logo-new.png" class="img-fluid" style="width: 200px;" />
              </a>

              <div style="width: 40px;"></div>

              <!-- Some horizontal space-->
              <a href="https://about.google/">
                  <img
                    src="../images/google-logo-new.png"
                    class="img-fluid"
                    style="width: 500px;"
                  />
              </a>
            </div>
        </div>
      </div>
    </section>

    <br />
    <hr class="half-rule" />
    <section id="contact">
      <div class="container">
        <div class="row">
          <div class="col-md-10 mx-auto">
            <span class="titlesec">Contact</span><br />
            <p>Reach out to
            <a href="mailto:scope2025@googlegroups.com"
              >scope2025@googlegroups.com</a
            > for any questions.</p>

            <h4>Volunteering as a Reviewer</h4>

            <p>If you would like to volunteer as a reviewer, please fill out <a href="https://docs.google.com/forms/d/e/1FAIpQLSd_Y8NpT7EQ_MrdUKKeioVIRKKqdpv5Zdn9fmgV1zkVNa58xQ/viewform">this form</a>.</p>
            <br />
          </div>
        </div>
      </div>
    </section>

    <!-- Footer -->

    <!-- Bootstrap core JavaScript -->
    <!-- 	<script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
	<script src="vendor/jquery/jquery.min.js"></script>
	<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
	<!-- Plugin JavaScript -->
    <!-- <script src="vendor/jquery-easing/jquery.easing.min.js"></script> -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>

    <!-- Custom JavaScript for this theme -->
    <script src="js/scrolling-nav.js"></script>
  </body>
</html>
